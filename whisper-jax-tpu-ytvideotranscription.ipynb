{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30459,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Whisper JAX ⚡️\n\nThis Kaggle notebook demonstratese how to run Whisper JAX on a TPU v3-8. Whisper JAX is a highly optimised JAX implementation of the Whisper model by OpenAI, largely built on the 🤗 Hugging Face Transformers Whisper implementation. Compared to OpenAI's PyTorch code, Whisper JAX runs over **70x faster**, making it the fastest Whisper implementation available.","metadata":{}},{"cell_type":"markdown","source":"# Straightforward Code\n---","metadata":{}},{"cell_type":"markdown","source":"## Install dependencies","metadata":{}},{"cell_type":"code","source":"!apt-get update -y\n!apt install -y ffmpeg\n!pip install --quiet --upgrade pip\n!pip install --quiet git+https://github.com/sanchit-gandhi/whisper-jax.git datasets soundfile librosa\n!pip install pytubefix\n!pip install gdown","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"# Suppress specific FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Load the PipeLine\nfrom whisper_jax import FlaxWhisperPipline\nimport jax.numpy as jnp\n\n# Initialize Compilation Cache\nfrom jax.experimental.compilation_cache import compilation_cache as cc\ncc.initialize_cache(\"./jax_cache\")\n\n# Load YouTube libraries and Link and others\nfrom pytubefix import YouTube \nimport os\nimport json\nfrom datetime import timedelta\n\n# Function\ndef format_timedelta(td):\n    \"\"\"Format timedelta to SRT timecode format (HH:MM:SS,MMM)\"\"\"\n    total_seconds = int(td.total_seconds())\n    hours, remainder = divmod(total_seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    milliseconds = td.microseconds // 1000\n    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run core script","metadata":{}},{"cell_type":"code","source":"timestamps = True\n\nmodel = \"openai/whisper-large-v2\" if timestamps else \"openai/whisper-large-v3\"\n\n# Check if 'pipeline' is None\nif pipeline is None:\n    pipeline = FlaxWhisperPipline(model, dtype=jnp.bfloat16, batch_size=16)\n\n# Continue with the rest of your code\n\n\nlink = input(\"Paste your YouTube link: \")\ntry: \n    # object creation using YouTube\n    # which was imported in the beginning \n    yt = YouTube(link) \n    print(\"Copied link. Success\")\nexcept: \n    print(\"Connection Error\")\n\n#streams_mp4 = yt.streams.filter(file_extension='mp4').first()\n\nprint(\"\\nDownloading YouTube audio....\\n\")\n\n# Define the stream and download it\nstream = yt.streams.get_by_itag(139)\nstream.download(output_path='.', filename='audio.mp3')\nYouTubeAudio='/kaggle/working/audio.mp3'\n\n# Check if 'train_audio.mp3' exists in the current directory\nif not os.path.exists('train_audio.mp3'):\n    print(\"Training not done yet, proceding... (Should take around 1-2 minutes)\")\n    \n    # Run the pipeline on a short audio to cache\n    !wget \"https://nt.doveai.cloud/s/3ZAEHJcxTcWb5FS/download/train_audio.mp3\" -O \"train_audio.mp3\" > /dev/null 2>&1\n    \n    # JIT compile the forward call - slow, but we only do once\n    test_audio = \"train_audio.mp3\"\n    %time text = pipeline(test_audio)\n    \n    if timestamps:\n        # compile the forward call with timestamps - slow but we only do once\n        %time outputs = pipeline(test_audio, return_timestamps=True)\n        time_stamped_text = outputs[\"text\"]  # transcription\n        time_stamped_chunks = outputs[\"chunks\"]  # transcription + timestamps\n    \nelse:\n    print(\"Cache already loaded and Pipeline is ready, skipping training stage...\")\n    \n# used cached function thereafter - super fast!\nprint(\"\\nTranscribing audio... \\n\")\n%time text = pipeline(YouTubeAudio)\n\n# let's check our transcription - looks spot on!\nprint(\"Transcribed:\",text)\n\n# Extract the text value from the JSON dictionary\ntext_content = text.get(\"text\", \"\")\n\n# Save the transcription to a file\nwith open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as file:\n    file.write(text_content)\n    print(\"Saved file as: transcription.txt\")\n\n# If timestamps is ON we can proceed to do it as well\nif timestamps:\n    # use cached timestamps function - super fast!\n    %time outputs = pipeline(YouTubeAudio, return_timestamps=True)\n    time_stamped_text = outputs[\"text\"] \n    time_stamped_chunks = outputs[\"chunks\"]\n    \n    # Prepare the SRT content\n    srt_content = []\n    for i, chunk in enumerate(outputs[\"chunks\"], start=1):\n        if isinstance(chunk, dict):\n            start_time, end_time = chunk.get(\"timestamp\", (0, 0))\n            text = chunk.get(\"text\", \"\")\n\n            # Convert to timedelta objects for formatting\n            start_td = timedelta(seconds=start_time)\n            end_td = timedelta(seconds=end_time)\n\n            # Format timestamps\n            start_str = format_timedelta(start_td)\n            end_str = format_timedelta(end_td)\n\n            # Format the SRT entry\n            srt_entry = f\"{i}\\n{start_str} --> {end_str}\\n{text}\\n\"\n            srt_content.append(srt_entry)\n\n    # Write the SRT file\n    with open(\"timestamped_transcription.srt\", \"w\", encoding=\"utf-8\") as file:\n        file.writelines(srt_content)\n    \n    #print(\"Time stamped chunks: \", time_stamped_chunks)\n    print(\"Saved file as: timestamped_transcription.txt\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T10:14:10.912130Z","iopub.execute_input":"2024-09-19T10:14:10.913062Z","iopub.status.idle":"2024-09-19T10:14:39.782699Z","shell.execute_reply.started":"2024-09-19T10:14:10.913020Z","shell.execute_reply":"2024-09-19T10:14:39.781535Z"},"trusted":true},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdin","text":"Paste your YouTube link:  https://www.youtube.com/watch?v=v9oFC3Vt9sU\n"},{"name":"stdout","text":"Copied link. Success\n\nDownloading YouTube audio....\n\nTraining not done yet, proceding... (Should take around 1-2 minutes)\n--2024-09-19 10:14:19--  https://nt.doveai.cloud/s/3ZAEHJcxTcWb5FS/download/train_audio.mp3\nResolving nt.doveai.cloud (nt.doveai.cloud)... 144.22.237.24\nConnecting to nt.doveai.cloud (nt.doveai.cloud)|144.22.237.24|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [audio/mpeg]\nSaving to: ‘train_audio.mp3’\n\ntrain_audio.mp3         [       <=>          ]   1.05M   887KB/s    in 1.2s    \n\n2024-09-19 10:14:21 (887 KB/s) - ‘train_audio.mp3’ saved [1097709]\n\nCPU times: user 11.6 s, sys: 20.4 s, total: 32 s\nWall time: 5.49 s\nCPU times: user 11.8 s, sys: 20.4 s, total: 32.2 s\nWall time: 2.71 s\n\nTranscribing audio... \n\nCPU times: user 25.8 s, sys: 45.3 s, total: 1min 11s\nWall time: 6.43 s\nTranscribed: {'text': ' 성훈아 안녕? 오랜만이다 너 성훈이 맞지? 저요? 저 아닌데요? 너 성훈이 아니라고? 네 내가 아는 성훈이 맞는데? 저는 준영이에요 준영이라고? 혹시 개명했어? 아니요 저는 날짜부터 준영이었는데요 아니야 너 성훈이 맞잖아! 진짜 사람 잘못 보셨나 봐요 아닌데? 너 인천 송림동 사는 성은이 맞지? 아니요 저는 김포 사는 데요. 진짜로 아니에요. 아니라고? 네. 진짜 아니에요? 네. 어? 오랜만이다 우리 고등학교 같이 다녔지 않아? 네? 저희 고등학교 같이 다니시지 않았어요? 남고나가서 아 남고요? 아하.. 도은아! 야 도은아! 야 안녕? 잘 지냈어? 네? 도은이? 나 채은이야! 채은이? 기억 안나? 우리 옛날에 같이 수학학원 다녔잖아? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리? 어? 우리! 안녕? 잘 지냈어? 나 채은이야! 기억 안나? 우리 옛날에 같이 수학학원 다녔잖아. 너 맨날 숙제 안해서 혼나고. 그랬나? 여자친구세요? 둘이 너무 잘 어울리세요. 아, 너는 좀 연락 좀 하고. 안녕히 계세요. 채은아! 너 진짜 오랜만이다. 세윤아, 나 기억 안 나? 네? 나 채연이야. 너 왜 여기서 뭐해? 네? 저... 아닌데요? 너 세윤이 맞잖아. 뭐요? 우리 옛날에 같이 옷도 사고, 맛있는 것도 먹고 그러고 놀았잖아. 아니요, 그런 거 없는데. 혹시 그럼 이름 뭐예요? 저 송수빈이요. 수빈이에요? 아닌데. 세은인데. 그럼 쌍둥이에요? 저 외정인데요. 아닌데. 너무 똑같은데. 네. 아닌데요. 야. 너 여기서 뭐해? 진짜 오랜만이다 저 아세요? 나 알지 나 몰라? 모르겠는데? 나 채은이잖아 채은이? 어 기억 안나? 왜 이렇게 연락 안했어? 번호가 없어요 번호도 지운거야? 아니요. 전혀 번호가 없는데? 다음에 연락해. 잘 있어 you'}\nSaved file as: transcription.txt\nCPU times: user 26.4 s, sys: 45.3 s, total: 1min 11s\nWall time: 3.63 s\nSaved file as: timestamped_transcription.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prepare the SRT content\nsrt_content = []\nfor i, chunk in enumerate(outputs[\"chunks\"], start=1):\n    if isinstance(chunk, dict):\n        start_time, end_time = chunk.get(\"timestamp\", (0, 0))\n        text = chunk.get(\"text\", \"\")\n        \n        # Convert to timedelta objects for formatting\n        start_td = timedelta(seconds=start_time)\n        end_td = timedelta(seconds=end_time)\n        \n        # Format timestamps\n        start_str = format_timedelta(start_td)\n        end_str = format_timedelta(end_td)\n        \n        # Format the SRT entry\n        srt_entry = f\"{i}\\n{start_str} --> {end_str}\\n{text}\\n\"\n        srt_content.append(srt_entry)\n\n# Write the SRT file\nwith open(\"timestamped_transcription.srt\", \"w\", encoding=\"utf-8\") as file:\n    file.writelines(srt_content)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T10:10:21.401396Z","iopub.execute_input":"2024-09-19T10:10:21.402393Z","iopub.status.idle":"2024-09-19T10:10:21.411261Z","shell.execute_reply.started":"2024-09-19T10:10:21.402355Z","shell.execute_reply":"2024-09-19T10:10:21.410221Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Short section (for cached pipeline)","metadata":{}},{"cell_type":"code","source":"# Once cached - You can run this (No timestamp)\n\nlink = input(\"Paste your YouTube link: \")\ntry: \n    # object creation using YouTube\n    # which was imported in the beginning \n    yt = YouTube(link) \n    print(\"Copied link. Success\")\nexcept: \n    print(\"Connection Error\")\n\nprint(\"\\nDownloading YouTube audio....\\n\")\n\n# Define the stream and download it\nstream = yt.streams.get_by_itag(139)\nstream.download(output_path='.', filename='audio.mp3')\nYouTubeAudio='/kaggle/working/audio.mp3'\n\n# JIT compile the forward call - slow, but we only do once\nprint(\"\\nTranscribing audio... \\n\")\ntest_audio = \"train_audio.mp3\"\n%time text = pipeline(YouTubeAudio)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}