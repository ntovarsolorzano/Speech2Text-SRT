{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30459,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Whisper JAX âš¡ï¸\n\nThis Kaggle notebook demonstratese how to run Whisper JAX on a TPU v3-8. Whisper JAX is a highly optimised JAX implementation of the Whisper model by OpenAI, largely built on the ðŸ¤— Hugging Face Transformers Whisper implementation. Compared to OpenAI's PyTorch code, Whisper JAX runs over **70x faster**, making it the fastest Whisper implementation available.","metadata":{}},{"cell_type":"markdown","source":"# Straightforward Code\n---","metadata":{}},{"cell_type":"markdown","source":"## Install dependencies","metadata":{}},{"cell_type":"code","source":"!apt-get update -y\n!apt install -y ffmpeg\n!pip install --quiet --upgrade pip\n!pip install --quiet git+https://github.com/sanchit-gandhi/whisper-jax.git datasets soundfile librosa\n!pip install pytubefix\n!pip install gdown","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"# Suppress specific FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Load the PipeLine\nfrom whisper_jax import FlaxWhisperPipline\nimport jax.numpy as jnp\n\n# Initialize Compilation Cache\nfrom jax.experimental.compilation_cache import compilation_cache as cc\ncc.initialize_cache(\"./jax_cache\")\n\n# Load YouTube libraries and Link and others\nfrom pytubefix import YouTube \nimport os\nimport json\nfrom datetime import timedelta\n\n# Function\ndef format_timedelta(td):\n    \"\"\"Format timedelta to SRT timecode format (HH:MM:SS,MMM)\"\"\"\n    total_seconds = int(td.total_seconds())\n    hours, remainder = divmod(total_seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    milliseconds = td.microseconds // 1000\n    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run core script","metadata":{}},{"cell_type":"code","source":"timestamps = True\n\nmodel = \"openai/whisper-large-v2\" if timestamps else \"openai/whisper-large-v3\"\n\n# Check if 'pipeline' is None\nif pipeline is None:\n    pipeline = FlaxWhisperPipline(model, dtype=jnp.bfloat16, batch_size=16)\n\n# Continue with the rest of your code\n\n\nlink = input(\"Paste your YouTube link: \")\ntry: \n    # object creation using YouTube\n    # which was imported in the beginning \n    yt = YouTube(link) \n    print(\"Copied link. Success\")\nexcept: \n    print(\"Connection Error\")\n\n#streams_mp4 = yt.streams.filter(file_extension='mp4').first()\n\nprint(\"\\nDownloading YouTube audio....\\n\")\n\n# Define the stream and download it\nstream = yt.streams.get_by_itag(139)\nstream.download(output_path='.', filename='audio.mp3')\nYouTubeAudio='/kaggle/working/audio.mp3'\n\n# Check if 'train_audio.mp3' exists in the current directory\nif not os.path.exists('train_audio.mp3'):\n    print(\"Training not done yet, proceding... (Should take around 1-2 minutes)\")\n    \n    # Run the pipeline on a short audio to cache\n    !wget \"https://nt.doveai.cloud/s/3ZAEHJcxTcWb5FS/download/train_audio.mp3\" -O \"train_audio.mp3\" > /dev/null 2>&1\n    \n    # JIT compile the forward call - slow, but we only do once\n    test_audio = \"train_audio.mp3\"\n    %time text = pipeline(test_audio)\n    \n    if timestamps:\n        # compile the forward call with timestamps - slow but we only do once\n        %time outputs = pipeline(test_audio, return_timestamps=True)\n        time_stamped_text = outputs[\"text\"]  # transcription\n        time_stamped_chunks = outputs[\"chunks\"]  # transcription + timestamps\n    \nelse:\n    print(\"Cache already loaded and Pipeline is ready, skipping training stage...\")\n    \n# used cached function thereafter - super fast!\nprint(\"\\nTranscribing audio... \\n\")\n%time text = pipeline(YouTubeAudio)\n\n# let's check our transcription - looks spot on!\nprint(\"Transcribed:\",text)\n\n# Extract the text value from the JSON dictionary\ntext_content = text.get(\"text\", \"\")\n\n# Save the transcription to a file\nwith open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as file:\n    file.write(text_content)\n    print(\"Saved file as: transcription.txt\")\n\n# If timestamps is ON we can proceed to do it as well\nif timestamps:\n    # use cached timestamps function - super fast!\n    %time outputs = pipeline(YouTubeAudio, return_timestamps=True)\n    time_stamped_text = outputs[\"text\"] \n    time_stamped_chunks = outputs[\"chunks\"]\n    \n    # Prepare the SRT content\n    srt_content = []\n    for i, chunk in enumerate(outputs[\"chunks\"], start=1):\n        if isinstance(chunk, dict):\n            start_time, end_time = chunk.get(\"timestamp\", (0, 0))\n            text = chunk.get(\"text\", \"\")\n\n            # Convert to timedelta objects for formatting\n            start_td = timedelta(seconds=start_time)\n            end_td = timedelta(seconds=end_time)\n\n            # Format timestamps\n            start_str = format_timedelta(start_td)\n            end_str = format_timedelta(end_td)\n\n            # Format the SRT entry\n            srt_entry = f\"{i}\\n{start_str} --> {end_str}\\n{text}\\n\"\n            srt_content.append(srt_entry)\n\n    # Write the SRT file\n    with open(\"timestamped_transcription.srt\", \"w\", encoding=\"utf-8\") as file:\n        file.writelines(srt_content)\n    \n    #print(\"Time stamped chunks: \", time_stamped_chunks)\n    print(\"Saved file as: timestamped_transcription.txt\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T10:14:10.912130Z","iopub.execute_input":"2024-09-19T10:14:10.913062Z","iopub.status.idle":"2024-09-19T10:14:39.782699Z","shell.execute_reply.started":"2024-09-19T10:14:10.913020Z","shell.execute_reply":"2024-09-19T10:14:39.781535Z"},"trusted":true},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdin","text":"Paste your YouTube link:  https://www.youtube.com/watch?v=v9oFC3Vt9sU\n"},{"name":"stdout","text":"Copied link. Success\n\nDownloading YouTube audio....\n\nTraining not done yet, proceding... (Should take around 1-2 minutes)\n--2024-09-19 10:14:19--  https://nt.doveai.cloud/s/3ZAEHJcxTcWb5FS/download/train_audio.mp3\nResolving nt.doveai.cloud (nt.doveai.cloud)... 144.22.237.24\nConnecting to nt.doveai.cloud (nt.doveai.cloud)|144.22.237.24|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [audio/mpeg]\nSaving to: â€˜train_audio.mp3â€™\n\ntrain_audio.mp3         [       <=>          ]   1.05M   887KB/s    in 1.2s    \n\n2024-09-19 10:14:21 (887 KB/s) - â€˜train_audio.mp3â€™ saved [1097709]\n\nCPU times: user 11.6 s, sys: 20.4 s, total: 32 s\nWall time: 5.49 s\nCPU times: user 11.8 s, sys: 20.4 s, total: 32.2 s\nWall time: 2.71 s\n\nTranscribing audio... \n\nCPU times: user 25.8 s, sys: 45.3 s, total: 1min 11s\nWall time: 6.43 s\nTranscribed: {'text': ' ì„±í›ˆì•„ ì•ˆë…•? ì˜¤ëžœë§Œì´ë‹¤ ë„ˆ ì„±í›ˆì´ ë§žì§€? ì €ìš”? ì € ì•„ë‹Œë°ìš”? ë„ˆ ì„±í›ˆì´ ì•„ë‹ˆë¼ê³ ? ë„¤ ë‚´ê°€ ì•„ëŠ” ì„±í›ˆì´ ë§žëŠ”ë°? ì €ëŠ” ì¤€ì˜ì´ì—ìš” ì¤€ì˜ì´ë¼ê³ ? í˜¹ì‹œ ê°œëª…í–ˆì–´? ì•„ë‹ˆìš” ì €ëŠ” ë‚ ì§œë¶€í„° ì¤€ì˜ì´ì—ˆëŠ”ë°ìš” ì•„ë‹ˆì•¼ ë„ˆ ì„±í›ˆì´ ë§žìž–ì•„! ì§„ì§œ ì‚¬ëžŒ ìž˜ëª» ë³´ì…¨ë‚˜ ë´ìš” ì•„ë‹Œë°? ë„ˆ ì¸ì²œ ì†¡ë¦¼ë™ ì‚¬ëŠ” ì„±ì€ì´ ë§žì§€? ì•„ë‹ˆìš” ì €ëŠ” ê¹€í¬ ì‚¬ëŠ” ë°ìš”. ì§„ì§œë¡œ ì•„ë‹ˆì—ìš”. ì•„ë‹ˆë¼ê³ ? ë„¤. ì§„ì§œ ì•„ë‹ˆì—ìš”? ë„¤. ì–´? ì˜¤ëžœë§Œì´ë‹¤ ìš°ë¦¬ ê³ ë“±í•™êµ ê°™ì´ ë‹¤ë…”ì§€ ì•Šì•„? ë„¤? ì €í¬ ê³ ë“±í•™êµ ê°™ì´ ë‹¤ë‹ˆì‹œì§€ ì•Šì•˜ì–´ìš”? ë‚¨ê³ ë‚˜ê°€ì„œ ì•„ ë‚¨ê³ ìš”? ì•„í•˜.. ë„ì€ì•„! ì•¼ ë„ì€ì•„! ì•¼ ì•ˆë…•? ìž˜ ì§€ëƒˆì–´? ë„¤? ë„ì€ì´? ë‚˜ ì±„ì€ì´ì•¼! ì±„ì€ì´? ê¸°ì–µ ì•ˆë‚˜? ìš°ë¦¬ ì˜›ë‚ ì— ê°™ì´ ìˆ˜í•™í•™ì› ë‹¤ë…”ìž–ì•„? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬? ì–´? ìš°ë¦¬! ì•ˆë…•? ìž˜ ì§€ëƒˆì–´? ë‚˜ ì±„ì€ì´ì•¼! ê¸°ì–µ ì•ˆë‚˜? ìš°ë¦¬ ì˜›ë‚ ì— ê°™ì´ ìˆ˜í•™í•™ì› ë‹¤ë…”ìž–ì•„. ë„ˆ ë§¨ë‚  ìˆ™ì œ ì•ˆí•´ì„œ í˜¼ë‚˜ê³ . ê·¸ëž¬ë‚˜? ì—¬ìžì¹œêµ¬ì„¸ìš”? ë‘˜ì´ ë„ˆë¬´ ìž˜ ì–´ìš¸ë¦¬ì„¸ìš”. ì•„, ë„ˆëŠ” ì¢€ ì—°ë½ ì¢€ í•˜ê³ . ì•ˆë…•ížˆ ê³„ì„¸ìš”. ì±„ì€ì•„! ë„ˆ ì§„ì§œ ì˜¤ëžœë§Œì´ë‹¤. ì„¸ìœ¤ì•„, ë‚˜ ê¸°ì–µ ì•ˆ ë‚˜? ë„¤? ë‚˜ ì±„ì—°ì´ì•¼. ë„ˆ ì™œ ì—¬ê¸°ì„œ ë­í•´? ë„¤? ì €... ì•„ë‹Œë°ìš”? ë„ˆ ì„¸ìœ¤ì´ ë§žìž–ì•„. ë­ìš”? ìš°ë¦¬ ì˜›ë‚ ì— ê°™ì´ ì˜·ë„ ì‚¬ê³ , ë§›ìžˆëŠ” ê²ƒë„ ë¨¹ê³  ê·¸ëŸ¬ê³  ë†€ì•˜ìž–ì•„. ì•„ë‹ˆìš”, ê·¸ëŸ° ê±° ì—†ëŠ”ë°. í˜¹ì‹œ ê·¸ëŸ¼ ì´ë¦„ ë­ì˜ˆìš”? ì € ì†¡ìˆ˜ë¹ˆì´ìš”. ìˆ˜ë¹ˆì´ì—ìš”? ì•„ë‹Œë°. ì„¸ì€ì¸ë°. ê·¸ëŸ¼ ìŒë‘¥ì´ì—ìš”? ì € ì™¸ì •ì¸ë°ìš”. ì•„ë‹Œë°. ë„ˆë¬´ ë˜‘ê°™ì€ë°. ë„¤. ì•„ë‹Œë°ìš”. ì•¼. ë„ˆ ì—¬ê¸°ì„œ ë­í•´? ì§„ì§œ ì˜¤ëžœë§Œì´ë‹¤ ì € ì•„ì„¸ìš”? ë‚˜ ì•Œì§€ ë‚˜ ëª°ë¼? ëª¨ë¥´ê² ëŠ”ë°? ë‚˜ ì±„ì€ì´ìž–ì•„ ì±„ì€ì´? ì–´ ê¸°ì–µ ì•ˆë‚˜? ì™œ ì´ë ‡ê²Œ ì—°ë½ ì•ˆí–ˆì–´? ë²ˆí˜¸ê°€ ì—†ì–´ìš” ë²ˆí˜¸ë„ ì§€ìš´ê±°ì•¼? ì•„ë‹ˆìš”. ì „í˜€ ë²ˆí˜¸ê°€ ì—†ëŠ”ë°? ë‹¤ìŒì— ì—°ë½í•´. ìž˜ ìžˆì–´ you'}\nSaved file as: transcription.txt\nCPU times: user 26.4 s, sys: 45.3 s, total: 1min 11s\nWall time: 3.63 s\nSaved file as: timestamped_transcription.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prepare the SRT content\nsrt_content = []\nfor i, chunk in enumerate(outputs[\"chunks\"], start=1):\n    if isinstance(chunk, dict):\n        start_time, end_time = chunk.get(\"timestamp\", (0, 0))\n        text = chunk.get(\"text\", \"\")\n        \n        # Convert to timedelta objects for formatting\n        start_td = timedelta(seconds=start_time)\n        end_td = timedelta(seconds=end_time)\n        \n        # Format timestamps\n        start_str = format_timedelta(start_td)\n        end_str = format_timedelta(end_td)\n        \n        # Format the SRT entry\n        srt_entry = f\"{i}\\n{start_str} --> {end_str}\\n{text}\\n\"\n        srt_content.append(srt_entry)\n\n# Write the SRT file\nwith open(\"timestamped_transcription.srt\", \"w\", encoding=\"utf-8\") as file:\n    file.writelines(srt_content)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T10:10:21.401396Z","iopub.execute_input":"2024-09-19T10:10:21.402393Z","iopub.status.idle":"2024-09-19T10:10:21.411261Z","shell.execute_reply.started":"2024-09-19T10:10:21.402355Z","shell.execute_reply":"2024-09-19T10:10:21.410221Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Short section (for cached pipeline)","metadata":{}},{"cell_type":"code","source":"# Once cached - You can run this (No timestamp)\n\nlink = input(\"Paste your YouTube link: \")\ntry: \n    # object creation using YouTube\n    # which was imported in the beginning \n    yt = YouTube(link) \n    print(\"Copied link. Success\")\nexcept: \n    print(\"Connection Error\")\n\nprint(\"\\nDownloading YouTube audio....\\n\")\n\n# Define the stream and download it\nstream = yt.streams.get_by_itag(139)\nstream.download(output_path='.', filename='audio.mp3')\nYouTubeAudio='/kaggle/working/audio.mp3'\n\n# JIT compile the forward call - slow, but we only do once\nprint(\"\\nTranscribing audio... \\n\")\ntest_audio = \"train_audio.mp3\"\n%time text = pipeline(YouTubeAudio)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}