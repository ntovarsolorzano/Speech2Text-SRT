{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30459,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Whisper JAX ⚡️\n\nThis Kaggle notebook demonstratese how to run Whisper JAX on a TPU v3-8. Whisper JAX is a highly optimised JAX implementation of the Whisper model by OpenAI, largely built on the 🤗 Hugging Face Transformers Whisper implementation. Compared to OpenAI's PyTorch code, Whisper JAX runs over **70x faster**, making it the fastest Whisper implementation available.","metadata":{}},{"cell_type":"markdown","source":"# Straightforward Code\n---","metadata":{}},{"cell_type":"markdown","source":"## Install dependencies","metadata":{}},{"cell_type":"code","source":"!apt-get update -y\n!apt install -y ffmpeg\n!pip install --quiet --upgrade pip\n!pip install --quiet git+https://github.com/sanchit-gandhi/whisper-jax.git \n#!pip datasets soundfile librosa\n!pip install pytubefix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"# Suppress specific FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Load the PipeLine\nfrom whisper_jax import FlaxWhisperPipline\nimport jax.numpy as jnp\n\n# Initialize Compilation Cache\nfrom jax.experimental.compilation_cache import compilation_cache as cc\ncc.initialize_cache(\"./jax_cache\")\n\n# Load YouTube libraries and Link and others\nfrom pytubefix import YouTube \nimport os\nimport json\nfrom datetime import timedelta\nimport contextlib\n\n# Function\ndef format_timedelta(td):\n    \"\"\"Format timedelta to SRT timecode format (HH:MM:SS,MMM)\"\"\"\n    total_seconds = int(td.total_seconds())\n    hours, remainder = divmod(total_seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    milliseconds = td.microseconds // 1000\n    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run core script","metadata":{}},{"cell_type":"code","source":"timestamps = True\n\nmodel = \"openai/whisper-large-v2\" if timestamps else \"openai/whisper-large-v3\"\n\n# Check if 'pipeline' exists. Use contextlib.redirect_stdout to suppress output\nwith contextlib.redirect_stdout(None):\n    try:\n        # Try to access 'pipeline' to check if it exists\n        pipeline\n    except NameError:\n        # If 'pipeline' does not exist, initialize it\n        pipeline = FlaxWhisperPipline(model, dtype=jnp.bfloat16, batch_size=16)\n\nlink = input(\"Paste your YouTube link: \")\ntry: \n    # object creation using YouTube\n    # which was imported in the beginning \n    yt = YouTube(link) \n    print(\"Copied link. Success\")\nexcept: \n    print(\"Connection Error\")\n\n#streams_mp4 = yt.streams.filter(file_extension='mp4').first()\n\nprint(\"\\nDownloading YouTube audio....\\n\")\n\n# Define the stream and download it\nstream = yt.streams.get_by_itag(139)\nstream.download(output_path='.', filename='audio.mp3')\nYouTubeAudio='/kaggle/working/audio.mp3'\n\n# Check if 'train_audio.mp3' exists in the current directory\nif not os.path.exists('train_audio.mp3'):\n    print(\"Training not done yet, proceding... (Should take around 1-2 minutes)\")\n    \n    # Run the pipeline on a short audio to cache\n    !wget \"https://nt.doveai.cloud/s/3ZAEHJcxTcWb5FS/download/train_audio.mp3\" -O \"train_audio.mp3\" > /dev/null 2>&1\n    \n    # JIT compile the forward call - slow, but we only do once\n    test_audio = \"train_audio.mp3\"\n    %time text = pipeline(test_audio)\n    \n    if timestamps:\n        # compile the forward call with timestamps - slow but we only do once\n        %time outputs = pipeline(test_audio, return_timestamps=True)\n        time_stamped_text = outputs[\"text\"]  # transcription\n        time_stamped_chunks = outputs[\"chunks\"]  # transcription + timestamps\n    \nelse:\n    print(\"Cache already loaded and Pipeline is ready, skipping training stage...\")\n    \n# used cached function thereafter - super fast!\nprint(\"\\nTranscribing audio... \\n\")\n%time text = pipeline(YouTubeAudio)\n\n# Get the video title\nvideo_title = yt.title\n\n# Print the video title\nprint(\"\\nVideo Title:\", video_title,\"\\n\")\n\n# let's check our transcription - looks spot on!\nprint(\"Transcribed:\",text)\n\n# Extract the text value from the JSON dictionary\ntext_content = text.get(\"text\", \"\")\n\n# Save the transcription to a file\nwith open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as file:\n    file.write(text_content)\n    print(\"Saved file as: transcription.txt\")\n\n# If timestamps is ON we can proceed to do it as well\nif timestamps:\n    # use cached timestamps function - super fast!\n    %time outputs = pipeline(YouTubeAudio, return_timestamps=True)\n    time_stamped_text = outputs[\"text\"] \n    time_stamped_chunks = outputs[\"chunks\"]\n    \n    # Prepare the SRT content\n    srt_content = []\n    for i, chunk in enumerate(outputs[\"chunks\"], start=1):\n        if isinstance(chunk, dict):\n            start_time, end_time = chunk.get(\"timestamp\", (0, 0))\n            text = chunk.get(\"text\", \"\")\n\n            # Convert to timedelta objects for formatting\n            start_td = timedelta(seconds=start_time)\n            end_td = timedelta(seconds=end_time)\n\n            # Format timestamps\n            start_str = format_timedelta(start_td)\n            end_str = format_timedelta(end_td)\n\n            # Format the SRT entry\n            srt_entry = f\"{i}\\n{start_str} --> {end_str}\\n{text}\\n\"\n            srt_content.append(srt_entry)\n\n    # Write the SRT file\n    with open(\"timestamped_transcription.srt\", \"w\", encoding=\"utf-8\") as file:\n        file.writelines(srt_content)\n    \n    #print(\"Time stamped chunks: \", time_stamped_chunks)\n    print(\"Saved file as: timestamped_transcription.txt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Short section (for cached pipeline)","metadata":{}},{"cell_type":"code","source":"# Once cached - You can run this (No timestamp)\n\nlink = input(\"Paste your YouTube link: \")\ntry: \n    # object creation using YouTube\n    # which was imported in the beginning \n    yt = YouTube(link) \n    print(\"Copied link. Success\")\nexcept: \n    print(\"Connection Error\")\n\nprint(\"\\nDownloading YouTube audio....\\n\")\n\n# Define the stream and download it\nstream = yt.streams.get_by_itag(139)\nstream.download(output_path='.', filename='audio.mp3')\nYouTubeAudio='/kaggle/working/audio.mp3'\n\n# JIT compile the forward call - slow, but we only do once\nprint(\"\\nTranscribing audio... \\n\")\ntest_audio = \"train_audio.mp3\"\n%time text = pipeline(YouTubeAudio)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}